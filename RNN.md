# Recurrent Neural Network (RNN)

循環神經網路（Recurrent Neural Network，RNN）是一種設計來處理和`預測序列`數據的神經網路，專門用於處理`元素順序`重要的數據（例如`時間序列`、`句子`或`音頻信號`）。

## RNN的關鍵概念

1. **序列數據處理**：RNN擅長逐步處理序列數據。例如，在語言中，單詞的意義通常依賴於前面的單詞，而RNN能夠捕捉這種關係。

2. **前一步驟的記憶**：與傳統神經網路不同，RNN具有內部“記憶”，允許它保留序列中先前輸入的信息，從而有助於理解隨時間變化的上下文和依賴關係。

3. **隱藏狀態**：在序列的每一步中，RNN維持一個隱藏狀態，該狀態作為前一步驟的記憶。隨著每個新輸入的處理，隱藏狀態會更新，將信息從一個步驟傳遞到下一個。

4. **循環結構**：RNN在其架構中具有循環結構，相同的網路層會在每個時間步驟中反覆應用，這使得網路能夠在整個序列中保留一致的理解。

RNN 逐一處理輸入序列中的每個`元素`，並維持一個`隱藏狀態`以捕捉先`前元素`的資訊。

在每個時間步驟 $t$，RNN 網路接收一個`輸入向量`，並基於當前輸入 $x_t$ 和前一隱藏狀態 $h_{t-1}$來更新其隱藏狀態。

接著，從當前的隱藏狀態 $h_t$生成輸出 $y_t$。這可以用數學表示為：

- **隱藏狀態更新**： $h_t = f(W_{hh}h_{t-1} + W_{xh}x_t + b_h)$
  
- **輸出計算**：$y_t = g(W_{hy}h_t + b_y)$

其中， $W_{hh}$、$W_{xh}$ 和 $W_{hy}$ 是權重矩陣，$b_h$ 和 $b_y$ 是偏置向量 (bias vector)， $f$ 和 $g$ 是激活函數 (activation function)。由於時間步驟間的共享權重，RNN 能夠在序列的不同位置上實現廣泛的一般化 (generalize)。

標準的 RNN 在捕捉長期依賴關係時經常遇到困難，這主要是由於訓練過程中的`梯度消失`問題。